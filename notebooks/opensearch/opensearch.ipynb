{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Setup and Path Configuration\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import requests\n",
    "\n",
    "print(f\"Python Version: {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\")\n",
    "print(f\"Environment: {sys.executable}\")\n",
    "\n",
    "# Find project root and add to Python path\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == \"opensearch\" and current_dir.parent.name == \"notebooks\":\n",
    "    project_root = current_dir.parent.parent\n",
    "elif (current_dir / \"compose.yml\").exists():\n",
    "    project_root = current_dir\n",
    "else:\n",
    "    project_root = None\n",
    "\n",
    "if project_root and (project_root / \"compose.yml\").exists():\n",
    "    print(f\"Project root: {project_root}\")\n",
    "    sys.path.insert(0, str(project_root))\n",
    "else:\n",
    "    print(\"Missing compose.yml - check directory\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Infrastructure Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service Health Verification\n",
    "print(\"PREREQUISITE CHECK\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "services_to_test = {\n",
    "    \"FastAPI\": \"http://localhost:8000/api/v1/health\",\n",
    "    \"PostgreSQL (via API)\": \"http://localhost:8000/api/v1/health\", \n",
    "    \"OpenSearch\": \"http://localhost:9200/_cluster/health\",\n",
    "    \"Airflow\": \"http://localhost:8080/health\"  \n",
    "}\n",
    "\n",
    "all_healthy = True\n",
    "\n",
    "for service_name, url in services_to_test.items():\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            print(f\"✓ {service_name}: Healthy\")\n",
    "        else:\n",
    "            print(f\"✗ {service_name}: HTTP {response.status_code}\")\n",
    "            all_healthy = False\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(f\"✗ {service_name}: Not accessible\")\n",
    "        all_healthy = False\n",
    "    except Exception as e:\n",
    "        print(f\"✗ {service_name}: {type(e).__name__}\")\n",
    "        all_healthy = False\n",
    "\n",
    "print()\n",
    "if all_healthy:\n",
    "    print(\"All services healthy! Ready for OpenSearch integration.\")\n",
    "else:\n",
    "    print(\"Some services need attention. Please run: docker compose up --build\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. OpenSearch Client Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenSearch Client Setup\n",
    "from src.services.opensearch.factory import make_opensearch_client\n",
    "from opensearchpy import OpenSearch\n",
    "\n",
    "print(\"OPENSEARCH CLIENT SETUP\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create OpenSearch client using factory pattern\n",
    "opensearch_client = make_opensearch_client()\n",
    "\n",
    "# Override for notebook execution (localhost instead of container hostname)\n",
    "opensearch_client.host = \"http://localhost:9200\"\n",
    "opensearch_client.client = OpenSearch(\n",
    "    hosts=[\"http://localhost:9200\"],\n",
    "    http_compress=True,\n",
    "    use_ssl=False,\n",
    "    verify_certs=False,\n",
    "    ssl_assert_hostname=False,\n",
    "    ssl_show_warn=False,\n",
    ")\n",
    "\n",
    "print(f\"Client configured with host: {opensearch_client.host}\")\n",
    "print(f\"Index name: {opensearch_client.index_name}\")\n",
    "\n",
    "# Test health check\n",
    "is_healthy = opensearch_client.health_check()\n",
    "if is_healthy:\n",
    "    print(\"✓ OpenSearch health check: PASSED\")\n",
    "else:\n",
    "    print(\"✗ OpenSearch health check: FAILED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Index Configuration\n",
    "from src.services.opensearch.index_config import ARXIV_PAPERS_INDEX, ARXIV_PAPERS_MAPPING\n",
    "\n",
    "print(\"INDEX CONFIGURATION\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Index Name: {ARXIV_PAPERS_INDEX}\")\n",
    "print(f\"\\nKey Features:\")\n",
    "print(\"• Custom text analyzers for better search\")\n",
    "print(\"• Multi-field mapping (text + keyword)\")\n",
    "print(\"• 10 specialized fields for papers\")\n",
    "print(\"\\nField Types:\")\n",
    "\n",
    "properties = ARXIV_PAPERS_MAPPING[\"mappings\"][\"properties\"]\n",
    "for field_name, config in properties.items():\n",
    "    field_type = config.get(\"type\")\n",
    "    analyzer = config.get(\"analyzer\", \"\")\n",
    "    if analyzer:\n",
    "        print(f\"  • {field_name}: {field_type} [{analyzer}]\")\n",
    "    else:\n",
    "        print(f\"  • {field_name}: {field_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Index if it doesn't exist\n",
    "print(\"INDEX CREATION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    # Check if index already exists\n",
    "    index_exists = opensearch_client.client.indices.exists(index=opensearch_client.index_name)\n",
    "    \n",
    "    if index_exists:\n",
    "        print(f\"✓ Index '{opensearch_client.index_name}' already exists\")\n",
    "        \n",
    "        # Get current index statistics\n",
    "        stats = opensearch_client.get_index_stats()\n",
    "        if stats and 'error' not in stats:\n",
    "            print(f\"\\nCurrent Statistics:\")\n",
    "            print(f\"   Documents: {stats.get('document_count', 0)}\")\n",
    "            print(f\"   Size: {stats.get('size_in_bytes', 0):,} bytes\")\n",
    "    else:\n",
    "        print(f\"Creating new index: {opensearch_client.index_name}\")\n",
    "        \n",
    "        # Create the index with our custom mapping\n",
    "        success = opensearch_client.create_index()\n",
    "        \n",
    "        if success:\n",
    "            print(f\"✓ Index created successfully!\")\n",
    "        else:\n",
    "            print(f\"✗ Index creation failed\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error with index management: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Data Pipeline Results\n",
    "print(\"VERIFYING DATA PIPELINE\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "stats = opensearch_client.get_index_stats()\n",
    "\n",
    "if stats and 'error' not in stats:\n",
    "    doc_count = stats.get('document_count', 0)\n",
    "    \n",
    "    if doc_count > 0:\n",
    "        print(f\"✓ Success! Found {doc_count} documents in OpenSearch\")\n",
    "        \n",
    "        # Show sample papers\n",
    "        sample = opensearch_client.search_papers(\"*\", size=3)\n",
    "        if sample.get('hits'):\n",
    "            print(f\"\\nSample papers:\")\n",
    "            for i, paper in enumerate(sample['hits'], 1):\n",
    "                title = paper.get('title', 'Unknown')[:60]\n",
    "                print(f\"  {i}. {title}...\")\n",
    "    else:\n",
    "        print(\"⚠️  No documents in OpenSearch yet\")\n",
    "        print(\"\\nPlease run the Airflow DAG first (see instructions above)\")\n",
    "else:\n",
    "    print(\"✗ Could not retrieve index stats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Simple BM25 Search\n",
    "\n",
    "Let's start with a simple search to demonstrate BM25 scoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple BM25 Search\n",
    "print(\"SIMPLE BM25 SEARCH\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Change this to any word from your papers\n",
    "search_term = \"learning\"  # Try different terms!\n",
    "\n",
    "print(f\"Searching for: '{search_term}'\\n\")\n",
    "\n",
    "results = opensearch_client.search_papers(\n",
    "    query=search_term,\n",
    "    size=5\n",
    ")\n",
    "\n",
    "if results.get('hits'):\n",
    "    print(f\"Found {results.get('total', 0)} total matches\\n\")\n",
    "    \n",
    "    for i, paper in enumerate(results['hits'], 1):\n",
    "        print(f\"{i}. {paper.get('title', 'Unknown')[:70]}...\")\n",
    "        print(f\"   Score: {paper.get('score', 0):.2f}\")\n",
    "        print(f\"   arXiv ID: {paper.get('arxiv_id', 'N/A')}\\n\")\n",
    "else:\n",
    "    print(\"No results found. Try searching for:\")\n",
    "    print(\"  • 'neural', 'model', 'algorithm'\")\n",
    "    print(\"  • Use '*' to see all papers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced OpenSearch Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Match Query\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match Query - Search in title field\n",
    "print(\"MATCH QUERY - Single Field Search\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"title\": \"machine learning\"\n",
    "        }\n",
    "    },\n",
    "    \"size\": 3\n",
    "}\n",
    "\n",
    "response = opensearch_client.client.search(\n",
    "    index=opensearch_client.index_name,\n",
    "    body=query\n",
    ")\n",
    "\n",
    "print(f\"Found {response['hits']['total']['value']} results\\n\")\n",
    "\n",
    "for hit in response['hits']['hits']:\n",
    "    print(f\"Title: {hit['_source']['title'][:70]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Multi-Match Query\n",
    "\n",
    "Search across multiple fields simultaneously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Match Query - Search across multiple fields\n",
    "print(\"MULTI-MATCH QUERY - Search Multiple Fields\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"multi_match\": {\n",
    "            \"query\": \"AI Agents\",\n",
    "            \"fields\": [\"title^2\", \"abstract\", \"authors\"],  # ^2 boosts title field\n",
    "            \"type\": \"best_fields\"\n",
    "        }\n",
    "    },\n",
    "    \"size\": 3\n",
    "}\n",
    "\n",
    "response = opensearch_client.client.search(\n",
    "    index=opensearch_client.index_name,\n",
    "    body=query\n",
    ")\n",
    "\n",
    "print(f\"Found {response['hits']['total']['value']} results\\n\")\n",
    "\n",
    "for hit in response['hits']['hits']:\n",
    "    print(f\"Title: {hit['_source']['title'][:70]}...\")\n",
    "    print(f\"Score: {hit['_score']:.2f}\")\n",
    "    print(f\"Authors: {', '.join(hit['_source']['authors'][:2])}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Boosting Query\n",
    "\n",
    "Boost certain results while demoting others:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting Query - Promote and demote results\n",
    "print(\"BOOSTING QUERY - Promote/Demote Results\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"boosting\": {\n",
    "            \"positive\": {\n",
    "                \"match\": {\n",
    "                    \"abstract\": \"deep learning\"\n",
    "                }\n",
    "            },\n",
    "            \"negative\": {\n",
    "                \"match\": {\n",
    "                    \"abstract\": \"multimodal\"\n",
    "                }\n",
    "            },\n",
    "            \"negative_boost\": 0.1  # Reduce score of negative matches\n",
    "        }\n",
    "    },\n",
    "    \"size\": 3\n",
    "}\n",
    "\n",
    "response = opensearch_client.client.search(\n",
    "    index=opensearch_client.index_name,\n",
    "    body=query\n",
    ")\n",
    "\n",
    "print(f\"Query: Boost 'deep learning', demote 'survey' papers\\n\")\n",
    "print(f\"Found {response['hits']['total']['value']} results\\n\")\n",
    "\n",
    "for hit in response['hits']['hits']:\n",
    "    title = hit['_source']['title'][:70]\n",
    "    abstract_snippet = hit['_source']['abstract'][:100]\n",
    "    print(f\"Title: {title}...\")\n",
    "    print(f\"Score: {hit['_score']:.2f}\")\n",
    "    print(f\"Abstract: {abstract_snippet}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Filter Query\n",
    "\n",
    "Filter results by specific criteria (doesn't affect scoring):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Query - Filter by categories\n",
    "print(\"FILTER QUERY - Category Filtering\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\n",
    "                    \"match\": {\n",
    "                        \"abstract\": \"neural\"\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            \"filter\": [\n",
    "                {\n",
    "                    \"terms\": {\n",
    "                        \"categories\": [\"cs.AI\"]\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"size\": 3\n",
    "}\n",
    "\n",
    "response = opensearch_client.client.search(\n",
    "    index=opensearch_client.index_name,\n",
    "    body=query\n",
    ")\n",
    "\n",
    "print(f\"Found {response['hits']['total']['value']} results\\n\")\n",
    "\n",
    "for hit in response['hits']['hits']:\n",
    "    title = hit['_source']['title'][:70]\n",
    "    categories = ', '.join(hit['_source']['categories'])\n",
    "    print(f\"Title: {title}...\")\n",
    "    print(f\"Categories: {categories}\")\n",
    "    print(f\"Score: {hit['_score']:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Sorting Query\n",
    "\n",
    "Sort results by different criteria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting Query - Sort by publication date\n",
    "print(\"SORTING QUERY - Latest Papers First\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"match_all\": {}  # Get all papers\n",
    "    },\n",
    "    \"sort\": [\n",
    "        {\n",
    "            \"published_date\": {\n",
    "                \"order\": \"desc\"  # Latest first\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"size\": 5\n",
    "}\n",
    "\n",
    "response = opensearch_client.client.search(\n",
    "    index=opensearch_client.index_name,\n",
    "    body=query\n",
    ")\n",
    "\n",
    "print(f\"Query: All papers sorted by publication date (newest first)\\n\")\n",
    "\n",
    "for hit in response['hits']['hits']:\n",
    "    title = hit['_source']['title'][:70]\n",
    "    pub_date = hit['_source']['published_date'][:10]\n",
    "    print(f\"Date: {pub_date} | {title}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Combined Query\n",
    "\n",
    "Combine multiple query types for complex searches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined Query - Complex search with multiple criteria\n",
    "print(\"COMBINED QUERY - Complex Search\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": \"transformer\",\n",
    "                        \"fields\": [\"title^3\", \"abstract\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            \"filter\": [\n",
    "                {\n",
    "                    \"range\": {\n",
    "                        \"published_date\": {\n",
    "                            \"gte\": \"2024-01-01\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            \"should\": [\n",
    "                {\n",
    "                    \"match\": {\n",
    "                        \"categories\": \"cs.AI\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"sort\": [\n",
    "        \"_score\",\n",
    "        {\"published_date\": {\"order\": \"desc\"}}\n",
    "    ],\n",
    "    \"size\": 3\n",
    "}\n",
    "\n",
    "response = opensearch_client.client.search(\n",
    "    index=opensearch_client.index_name,\n",
    "    body=query\n",
    ")\n",
    "\n",
    "print(f\"Complex Query:\")\n",
    "print(f\"  • Must contain 'transformer' (title boosted 3x)\")\n",
    "print(f\"  • Filter: published after 2024-01-01\")\n",
    "print(f\"  • Prefer: cs.AI category\")\n",
    "print(f\"  • Sort: by relevance, then date\\n\")\n",
    "\n",
    "print(f\"Found {response['hits']['total']['value']} results\\n\")\n",
    "\n",
    "for hit in response['hits']['hits']:\n",
    "    title = hit['_source']['title'][:70]\n",
    "    pub_date = hit['_source']['published_date'][:10]\n",
    "    score = hit['_score']\n",
    "    categories = ', '.join(hit['_source']['categories'][:2])\n",
    "    \n",
    "    print(f\"Title: {title}...\")\n",
    "    print(f\"  Date: {pub_date} | Score: {score:.2f}\")\n",
    "    print(f\"  Categories: {categories}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
